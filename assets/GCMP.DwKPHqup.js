import{_ as f}from"./ValaxyMain.vue_vue_type_style_index_0_lang.BXDscpob.js";import{e as g,u as k,a as b}from"./chunks/vue-router.fX0UCdQ5.js";import{ab as v,al as e,ad as a,ae as i,P as y,ai as t,B as c,a9 as C,aa as E,D as P}from"./framework.53SfwQWC.js";import"./app.D8_-IYO0.js";import"./chunks/dayjs.BdcnXKr1.js";import"./chunks/vue-i18n.BEnJbYsC.js";import"./chunks/pinia.BvWP5_ZP.js";/* empty css                    */import"./chunks/@vueuse/motion.Q6KdVLqP.js";import"./chunks/nprogress.Bru8d7fl.js";import"./YunComment.vue_vue_type_style_index_0_lang.BX7mt8JC.js";import"./index.C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang.DWvzorTa.js";import"./post.Db7D0una.js";const w={class:"info custom-block"},x={class:"custom-block-title custom-block-title-default"},M=g("/posts/GCMP",async n=>JSON.parse('{"title":"GCMP","description":"","frontmatter":{"title":"GCMP","tags":["AI"],"categories":"AI","date":"2026-02-07","updated":"2026-02-07"},"headers":[],"relativePath":"pages/posts/GCMP.md","lastUpdated":1770816529000}'),{lazy:(n,s)=>n.name===s.name}),L={__name:"GCMP",setup(n,{expose:s}){const{data:d}=M(),u=b(),p=k(),r=Object.assign(p.meta.frontmatter||{},d.value?.frontmatter||{});return u.currentRoute.value.data=d.value,P("valaxy:frontmatter",r),globalThis.$frontmatter=r,s({frontmatter:{title:"GCMP",tags:["AI"],categories:"AI",date:"2026-02-07",updated:"2026-02-07"}}),(o,l)=>{const h=C("VT"),m=f;return E(),v(m,{frontmatter:c(r)},{"main-content-md":e(()=>[l[1]||(l[1]=i("nav",{class:"table-of-contents"},[i("ul",null,[i("li",null,[i("a",{href:"#overview"},"Overview")]),i("li",null,[i("a",{href:"#what-gcmp-actually-solves"},"What GCMP Actually Solves")]),i("li",null,[i("a",{href:"#built-in-provider-coverage"},"Built-In Provider Coverage")]),i("li",null,[i("a",{href:"#installation-and-first-run"},"Installation and First Run")]),i("li",null,[i("a",{href:"#why-it-feels-powerful-in-practice"},"Why It Feels Powerful in Practice"),i("ul",null,[i("li",null,[i("a",{href:"#_1-regional-and-provider-flexibility"},"1. Regional and provider flexibility")]),i("li",null,[i("a",{href:"#_2-strong-customization-path"},"2. Strong customization path")]),i("li",null,[i("a",{href:"#_3-more-than-just-chat"},"3. More than just chat")])])]),i("li",null,[i("a",{href:"#example-configuration-direction"},"Example Configuration Direction")]),i("li",null,[i("a",{href:"#good-fit-vs-not-a-good-fit"},"Good Fit vs. Not a Good Fit")]),i("li",null,[i("a",{href:"#final-thoughts"},"Final Thoughts")]),i("li",null,[i("a",{href:"#what-s-next"},"What’s Next")])])],-1)),i("div",w,[i("p",x,[y(h,{content:"blocks.info"})]),l[0]||(l[0]=i("p",null,[t("Source: "),i("a",{href:"https://github.com/VicBilibily/GCMP",target:"_blank",rel:"noreferrer"},"GCMP"),t(" by "),i("a",{href:"https://github.com/VicBilibily",target:"_blank",rel:"noreferrer"},"VicBilibily")],-1))]),l[2]||(l[2]=i("h2",{id:"overview",tabindex:"-1"},[t("Overview "),i("a",{class:"header-anchor",href:"#overview","aria-label":'Permalink to "Overview"'},"​")],-1)),l[3]||(l[3]=i("p",null,[t("GCMP is a Visual Studio Code extension that expands the model choices available in GitHub Copilot Chat."),i("br"),t(" Like "),i("em",null,"Unify Chat Provider for Copilot"),t(", it acts as a bridge between Copilot’s chat experience and external LLM providers. The big difference is focus: GCMP is built around strong first-class support for Chinese-native model providers, while still supporting OpenAI/Anthropic-compatible endpoints.")],-1)),l[4]||(l[4]=i("p",null,"If you want Copilot Chat UX but broader model access, GCMP is one of the most practical options right now.",-1)),l[5]||(l[5]=i("h2",{id:"what-gcmp-actually-solves",tabindex:"-1"},[t("What GCMP Actually Solves "),i("a",{class:"header-anchor",href:"#what-gcmp-actually-solves","aria-label":'Permalink to "What GCMP Actually Solves"'},"​")],-1)),l[6]||(l[6]=i("p",null,"GitHub Copilot is excellent as a product, but model and provider flexibility can be limited depending on your region, budget, or preferred vendors. GCMP addresses that by letting you:",-1)),l[7]||(l[7]=i("ul",null,[i("li",null,"Use multiple model providers inside the Copilot Chat workflow"),i("li",null,"Bring your own API key per provider"),i("li",null,"Add OpenAI-compatible and Anthropic-compatible custom endpoints"),i("li",null,"Switch models quickly from the model picker without leaving VS Code")],-1)),l[8]||(l[8]=i("p",null,"In short: same chat workflow, many more model backends.",-1)),l[9]||(l[9]=i("h2",{id:"built-in-provider-coverage",tabindex:"-1"},[t("Built-In Provider Coverage "),i("a",{class:"header-anchor",href:"#built-in-provider-coverage","aria-label":'Permalink to "Built-In Provider Coverage"'},"​")],-1)),l[10]||(l[10]=i("p",null,"Based on the official repository, GCMP includes broad support for providers such as:",-1)),l[11]||(l[11]=i("ul",null,[i("li",null,"Zhipu AI (GLM series)"),i("li",null,"MiniMax"),i("li",null,"Moonshot AI (Kimi)"),i("li",null,"DeepSeek"),i("li",null,"Alibaba Cloud Bailian (Qwen family)"),i("li",null,"Volcengine Ark"),i("li",null,"Kuaishou StreamLake"),i("li",null,"Mthreads")],-1)),l[12]||(l[12]=i("p",null,"It also supports compatible provider modes so you can connect third-party gateways that follow OpenAI or Anthropic API conventions.",-1)),l[13]||(l[13]=i("h2",{id:"installation-and-first-run",tabindex:"-1"},[t("Installation and First Run "),i("a",{class:"header-anchor",href:"#installation-and-first-run","aria-label":'Permalink to "Installation and First Run"'},"​")],-1)),l[14]||(l[14]=i("ol",null,[i("li",null,[t("Open VS Code Extensions and install "),i("code",null,"GCMP"),t(" ("),i("code",null,"vicanent.gcmp"),t(").")]),i("li",null,[t("Open "),i("strong",null,"GitHub Copilot Chat"),t(".")]),i("li",null,[t("In the model selector, choose "),i("strong",null,"Manage Models"),t(".")]),i("li",null,"Pick a provider and configure its API key."),i("li",null,"Enable your target model and start chatting.")],-1)),l[15]||(l[15]=i("p",null,"That flow is straightforward, and it keeps everything inside VS Code’s native chat panel.",-1)),l[16]||(l[16]=i("h2",{id:"why-it-feels-powerful-in-practice",tabindex:"-1"},[t("Why It Feels Powerful in Practice "),i("a",{class:"header-anchor",href:"#why-it-feels-powerful-in-practice","aria-label":'Permalink to "Why It Feels Powerful in Practice"'},"​")],-1)),l[17]||(l[17]=i("h3",{id:"_1-regional-and-provider-flexibility",tabindex:"-1"},[t("1. Regional and provider flexibility "),i("a",{class:"header-anchor",href:"#_1-regional-and-provider-flexibility","aria-label":'Permalink to "1. Regional and provider flexibility"'},"​")],-1)),l[18]||(l[18]=i("p",null,"If your day-to-day stack includes domestic providers, GCMP removes a lot of friction. You can keep one editor workflow while choosing models that match your latency, pricing, and availability constraints.",-1)),l[19]||(l[19]=i("h3",{id:"_2-strong-customization-path",tabindex:"-1"},[t("2. Strong customization path "),i("a",{class:"header-anchor",href:"#_2-strong-customization-path","aria-label":'Permalink to "2. Strong customization path"'},"​")],-1)),l[20]||(l[20]=i("p",null,"GCMP exposes advanced settings for provider overrides and compatible models. That means you can tune:",-1)),l[21]||(l[21]=i("ul",null,[i("li",null,"Base URL"),i("li",null,"Headers"),i("li",null,"Model capabilities"),i("li",null,"Extra request body parameters")],-1)),l[22]||(l[22]=i("p",null,"This is especially useful when you rely on custom gateways or provider-specific options.",-1)),l[23]||(l[23]=i("h3",{id:"_3-more-than-just-chat",tabindex:"-1"},[t("3. More than just chat "),i("a",{class:"header-anchor",href:"#_3-more-than-just-chat","aria-label":'Permalink to "3. More than just chat"'},"​")],-1)),l[24]||(l[24]=i("p",null,"GCMP also includes:",-1)),l[25]||(l[25]=i("ul",null,[i("li",null,"Inline completion modes (FIM and NES)"),i("li",null,"Token usage statistics and status bar insights"),i("li",null,"Context window occupancy visibility"),i("li",null,"AI-assisted commit message generation")],-1)),l[26]||(l[26]=i("p",null,'So it is not only "chat model switching"; it is closer to a full Copilot-side enhancement layer.',-1)),l[27]||(l[27]=i("h2",{id:"example-configuration-direction",tabindex:"-1"},[t("Example Configuration Direction "),i("a",{class:"header-anchor",href:"#example-configuration-direction","aria-label":'Permalink to "Example Configuration Direction"'},"​")],-1)),l[28]||(l[28]=i("p",null,[t("You can configure model behavior through "),i("code",null,"settings.json"),t(", for example:")],-1)),l[29]||(l[29]=i("div",{class:"vp-code-block-title"},[i("div",{class:"vp-code-block-title-bar"},[i("span",{class:"vp-code-block-title-text","data-title":"settings.json"},"settings.json")]),i("div",{class:"language-json max-h-400px"},[i("button",{title:"Copy code",class:"copy"}),i("span",{class:"lang"},"json"),i("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[i("code",{"v-pre":""},[i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"{")]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},'  "gcmp.maxTokens"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},": "),i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},"16000"),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},",")]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},'  "gcmp.editToolMode"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},": "),i("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"}},'"gpt-5"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},",")]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},'  "gcmp.rememberLastModel"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},": "),i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},"true")]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"}")])])]),i("button",{class:"code-block-unfold-btn"})])],-1)),l[30]||(l[30]=i("p",null,"And for custom compatible models, GCMP supports rich provider/model definitions (including custom headers and extra body fields), which makes integration with OpenAI-compatible services much easier.",-1)),l[31]||(l[31]=i("h2",{id:"good-fit-vs-not-a-good-fit",tabindex:"-1"},[t("Good Fit vs. Not a Good Fit "),i("a",{class:"header-anchor",href:"#good-fit-vs-not-a-good-fit","aria-label":'Permalink to "Good Fit vs. Not a Good Fit"'},"​")],-1)),l[32]||(l[32]=i("p",null,"GCMP is a strong fit if you:",-1)),l[33]||(l[33]=i("ul",null,[i("li",null,"Want to stay in Copilot Chat but use many non-default models"),i("li",null,"Need Chinese-native providers as first-class options"),i("li",null,"Care about deeper control over model routing and parameters")],-1)),l[34]||(l[34]=i("p",null,"It may be overkill if you:",-1)),l[35]||(l[35]=i("ul",null,[i("li",null,"Only use one provider and never switch"),i("li",null,"Prefer a minimal setup with almost no configuration")],-1)),l[36]||(l[36]=i("h2",{id:"final-thoughts",tabindex:"-1"},[t("Final Thoughts "),i("a",{class:"header-anchor",href:"#final-thoughts","aria-label":'Permalink to "Final Thoughts"'},"​")],-1)),l[37]||(l[37]=i("p",null,[t("GCMP and Unify Chat Provider target a similar problem space: expanding Copilot’s model ecosystem."),i("br"),t(" GCMP stands out by combining broad provider support, practical regional coverage, and advanced configuration depth in a single extension.")],-1)),l[38]||(l[38]=i("p",null,"If your workflow depends on model optionality instead of vendor lock-in, GCMP is worth trying.",-1)),l[39]||(l[39]=i("h2",{id:"what-s-next",tabindex:"-1"},[t("What’s Next "),i("a",{class:"header-anchor",href:"#what-s-next","aria-label":`Permalink to "What's Next"`},"​")],-1)),l[40]||(l[40]=i("p",null,"There are also some other Vibe Coding extensions in VS Code, such as:",-1)),l[41]||(l[41]=i("ul",null,[i("li",null,[i("code",null,"Cline")]),i("li",null,[i("code",null,"Roo Code")]),i("li",null,[i("code",null,"Kilo Code")])],-1)),l[42]||(l[42]=i("p",null,"Simple Usage:",-1)),l[43]||(l[43]=i("div",{class:"vp-code-block-title"},[i("div",{class:"vp-code-block-title-bar"},[i("span",{class:"vp-code-block-title-text","data-title":"API config example"},"API config example")]),i("div",{class:"language-json max-h-400px"},[i("button",{title:"Copy code",class:"copy"}),i("span",{class:"lang"},"json"),i("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[i("code",{"v-pre":""},[i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"{")]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},'  "baseUrl"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},": "),i("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"}},'"https://example.com/v1"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},",")]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"}},'  "apiKey"'),i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},": "),i("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"}},'"YOUR_API_KEY"')]),t(`
`),i("span",{class:"line"},[i("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"}")])])]),i("button",{class:"code-block-unfold-btn"})])],-1))]),"main-header":e(()=>[a(o.$slots,"main-header")]),"main-header-after":e(()=>[a(o.$slots,"main-header-after")]),"main-nav":e(()=>[a(o.$slots,"main-nav")]),"main-content-before":e(()=>[a(o.$slots,"main-content-before")]),"main-content":e(()=>[a(o.$slots,"main-content")]),"main-content-after":e(()=>[a(o.$slots,"main-content-after")]),"main-nav-before":e(()=>[a(o.$slots,"main-nav-before")]),"main-nav-after":e(()=>[a(o.$slots,"main-nav-after")]),comment:e(()=>[a(o.$slots,"comment")]),footer:e(()=>[a(o.$slots,"footer")]),aside:e(()=>[a(o.$slots,"aside")]),"aside-custom":e(()=>[a(o.$slots,"aside-custom")]),default:e(()=>[a(o.$slots,"default")]),_:3},8,["frontmatter"])}}};export{L as default,M as usePageData};
